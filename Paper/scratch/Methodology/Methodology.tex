%% 
%% Template chap2.tex
%% 

% \chapter{Methodology}
% \label{cha:methodology}

\section{Learning the MRFs}
\label{sec:learning}

Traditional Support Vector Machines (SVMs) is used to solve
binary classification problem. \citename{crammer2002algorithmic}
extended SVM into multiclass classifier by generalizing the
concept of \emph{margin} to measure multiclass distances and a
quadratic objective function was constructed. To approach
structural prediction \citename{tsochantaridis2005large} extends
their approach by specifying discriminant functions that exploit
the structure and dependencies within label space $\Y$.

When training Structural SVMs, the parameter vector $\bw$ is
determined by minimizing the (regularized) risk on the training
set $(x_1,y_1),...,(x_n,y_n)$. Risk is measured through a
user-supplied loss function $\Delta(y,\hat{ y })$ that quantifies
how much the prediction $\hat{y}$ differs from the correct output
$y$. Note that $\Delta$ is typically nonconvex and discontinuous
and there are usually exponentially many possible structures
$\hat{y}$ in the output space $\Y$. The Structural SVM
formulation\cite{tsochantaridis2005large} overcomes these
difficulties by replacing the loss function $\Delta$ with a
piecewise linear convex upper bound (margin rescaling). To train
Structural SVMs we then solve the following convex optimization
problem

\begin{align}
  \label{eq:ssvm_objective}
  min_{\bw} \frac{1}{2}||\bw||^2+\C\sum_{i=1}^{n}\bigg[& max_{\hat{y}\in\Y}\big[\Delta(y_i,\hat{ y })+\bw\cdot\phi(x_i,\hat{y})\big]\notag \\
  & -\bw\cdot\phi(x_i,y_i)\bigg]
\end{align}

Despite the typically exponential size of $\Y$, this optimization
problem can be solved efficiently using cutting-plane or
stochastic gradient methods.

Let $\Y_t = \{0, 1\}^n$ be the set of all possible assignments
for the $t$-th training example. The (margin-rescaling)
max-margin approach formulates learning as a quadratic
programming optimization problem. Let

\begin{align*}
  \delta\phi_t(\by) \triangleq & \text{ }max_{\by\in\Y}\big[\Delta(\by_t,\by)+\bw\cdot\phi(x_t,\by)\big] \\
  & -\bw\cdot\phi(x_t,\by_t)
\end{align*}

\noindent be the difference between feature representations for
some assignment $\by$ and the $t$-th ground-truth assignment
$\by_t$, $C > 0$ is a regularization constant, and $\Delta(\by,
\by_t)$ measures the loss between a ground-truth assignment
$\by_t$ and any other assignment. In our work we use the Hamming
loss, which measures the proportion of variables whose
corresponding assignments disagree. More formally, the Hamming
loss is defined as $\Delta(\by, \by') = \frac{1}{n}
\sum_{i=1}^{n} \ind{y_i \neq y'_i}$, where $\ind{P}$ is the
indicator function taking value one when $P$ is true and zero
otherwise.

\begin{algorithm}[tb]
  \begin{algorithmic}[1]
    \STATE{ {\bf input} training set $\{\by_t\}_{t=1}^{T}$, regularization constant $C > 0$,
      and tolerance $\epsilon \geq 0$}
    \STATE{ {\bf initialize} active constraints set $\A_t = \{ \}$ for all $t$}
    \REPEAT

    \STATE{solve $\mmqp{\A_t}{\bD^2}{\zeros}$ to get $\hat{\btheta}$ and
      $\hat{\bxi}$}

    \STATE{convert from $\hat{\btheta}$ to $(a_k, b_k)$ representation}
    \FOR{each training example, $t = 1, \ldots, T$}
    \STATE{compute $\by_t^\star = \argmin_{\by} E(\by; \hat{\btheta}) - \Delta(\by, \by_t)$}
    \IF{$\hat{\xi}_t + \epsilon \!<\! \Delta(\by_t^\star, \by_t) -
      E(\by_t^\star; \hat{\btheta}) + E(\by_t; \hat{\btheta})$}
    \STATE{$\A_t \leftarrow \A_t \cup \{\by_t^\star\}$}
    \ENDIF
    \ENDFOR
    \UNTIL{no more violated constraints}
    \STATE{ {\bf return} parameters $\hat{\btheta}$}
  \end{algorithmic}
  \caption{\label{alg:learning} Learning lower linear envelope MRFs.}
\end{algorithm}

The number of constraints in the Quadratic Programming problem is
exponential in the number of variables, and a standard approach
to solving the max-margin QP is the cutting-plane algorithm.
Briefly, at each iteration the algorithm checks for the most
violated constraint. If found, it will be added into the
constraint set. The algorithm terminates when no more violated
constraints are found (see \algref{alg:learning}). Since the loss
function is subtracted from the energy function during
loss-augmented inference, the supermodular loss becomes a
submodular objective and therefore admits tractable minimization.


% % \clearpage
% % \cleardoublepage


% % %%% Local Variables:
% % %%% mode: latex
% % %%% TeX-master: "../thesis"
% % %%% End:
